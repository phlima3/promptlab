# PromptLab - AI Writing Workspace

**PromptLab** Ã© um monorepo TypeScript full-stack que fornece uma plataforma para criaÃ§Ã£o de templates de prompts e execuÃ§Ã£o de geraÃ§Ãµes de texto usando LLMs (OpenAI/Anthropic).

## ğŸ—ï¸ Arquitetura

- **apps/web** - Next.js UI (templates, geraÃ§Ã£o, status de jobs)
- **apps/api** - Express API (templates CRUD, endpoint de geraÃ§Ã£o, status de jobs)
- **apps/worker** - Processador de jobs em background (retry logic, timeouts)
- **packages/shared** - Schemas Zod + tipos TypeScript compartilhados
- **packages/db** - Prisma schema + client wrapper

## ğŸš€ Quick Start

### PrÃ©-requisitos

- Node.js 18+ e Yarn
- Docker (para PostgreSQL e Redis)

### 1. Instalar dependÃªncias

```bash
yarn install
```

### 2. Iniciar serviÃ§os de infraestrutura

```bash
docker compose up -d
```

Isso iniciarÃ¡:

- PostgreSQL na porta 5433
- Redis na porta 6379

### 3. Configurar variÃ¡veis de ambiente

Copie o `.env.example` para `.env` e ajuste se necessÃ¡rio:

```bash
cp .env.example .env
```

O arquivo jÃ¡ estÃ¡ configurado para usar os containers Docker.

### 4. Executar migrations do banco de dados

```bash
yarn db:migrate
```

### 5. Popular banco de dados com templates de exemplo

```bash
yarn db:seed
```

### 6. Iniciar aplicaÃ§Ã£o

Em terminais separados:

```bash
# Terminal 1: API
yarn workspace @promptlab/api dev

# Terminal 2: Worker
yarn workspace @promptlab/worker dev

# Terminal 3: Web (quando implementada)
yarn workspace web dev
```

Ou usar o comando turbo (inicia todos juntos):

```bash
yarn dev
```

## ğŸ§ª Testar o fluxo completo

Com a API e Worker rodando, execute:

```bash
yarn test:flow
```

Este script irÃ¡:

1. Listar templates disponÃ­veis
2. Submeter um job de geraÃ§Ã£o
3. Fazer polling do status
4. Exibir o resultado

## ğŸ“š API Endpoints

### Templates

**POST /templates**
Cria um novo template

```json
{
  "name": "Blog Post Writer",
  "systemPrompt": "You are a professional blog writer.",
  "userPrompt": "Write about: {{input}}",
  "variablesSchema": { "input": "string" }
}
```

**GET /templates**
Lista todos os templates

**GET /templates/:id**
ObtÃ©m um template especÃ­fico

### Generation

**POST /generate**
Cria um job de geraÃ§Ã£o

```json
{
  "templateId": "cm...",
  "provider": "openai",
  "input": "the benefits of TypeScript"
}
```

Retorna: `{ "jobId": "cm..." }`

**GET /jobs/:id**
ObtÃ©m status e resultado de um job

## ğŸ”‘ Design Decisions

### 1. Async by Default

Chamadas LLM sÃ£o assÃ­ncronas por padrÃ£o. O endpoint `/generate` retorna imediatamente com um `jobId` que pode ser consultado via polling.

### 2. Idempotency

Jobs com o mesmo `(templateId + provider + input + templateVersion)` nÃ£o criam trabalho duplicado. O sistema retorna o `jobId` existente.

### 3. Retry Logic

Worker implementa retry com backoff exponencial (1s, 3s, 10s) atÃ© 3 tentativas antes de marcar como falha.

### 4. Type Safety

Schemas Zod em `packages/shared` garantem validaÃ§Ã£o consistente entre frontend, API e worker.

### 5. Error Handling

Respostas de erro padronizadas:

```json
{
  "error": {
    "code": "validation_error | not_found | rate_limited | internal_error",
    "message": "human readable message",
    "details": {}
  }
}
```

## ğŸ“Š Database Schema

### Template

- `id`, `name`, `systemPrompt`, `userPrompt`
- `variablesSchema` (JSON), `version`
- Timestamps: `createdAt`, `updatedAt`

### Job

- `id`, `status` (queued/running/completed/failed)
- `templateId`, `provider`, `input`, `inputHash`
- `output`, `error`, `attempts`
- Timestamps: `startedAt`, `finishedAt`, `createdAt`, `updatedAt`

## ğŸ”§ Scripts Ãšteis

```bash
# Desenvolvimento
yarn dev                  # Inicia todos os apps
yarn typecheck           # Verifica tipos TypeScript
yarn build               # Build de produÃ§Ã£o

# Database
yarn db:migrate          # Roda migrations
yarn db:generate         # Gera Prisma Client
yarn db:seed            # Popula com dados de exemplo

# Testing
yarn test:flow          # Teste end-to-end do fluxo completo
```

## ğŸ¯ Roadmap (Next Steps)

### Fase 6 - LLM Provider Integration

- [ ] Implementar mÃ³dulo de provedor real (OpenAI/Anthropic)
- [ ] Adicionar logging de tokens e custos estimados
- [ ] Implementar timeouts e circuit breakers

### Fase 7 - Rate Limiting + Caching

- [ ] Redis-based rate limiting por usuÃ¡rio
- [ ] Cache de resultados por inputHash
- [ ] Implementar sliding window rate limiter

### Fase 8 - Redis Queue

- [ ] Migrar de polling para BullMQ
- [ ] Job priorities e concurrency control
- [ ] Dead letter queue para jobs falhos

### Fase 9 - UI (Next.js)

- [ ] PÃ¡gina de templates (criar/listar/editar)
- [ ] PÃ¡gina de geraÃ§Ã£o com live status updates
- [ ] HistÃ³rico de jobs e resultados

### Fase 10 - Production Ready

- [ ] WebSockets para job updates em tempo real
- [ ] Evaluation harness (prompt versioning + regression testing)
- [ ] Observabilidade: structured logging + metrics
- [ ] Multi-tenant + autenticaÃ§Ã£o JWT

## ğŸ† Interview-Ready Features

Este projeto demonstra:

âœ… **Full-stack TypeScript**: Next.js + Express + shared types  
âœ… **Backend maturity**: Validation, error handling, async jobs, retries  
âœ… **Database design**: Prisma, migrations, proper indexing  
âœ… **API design**: RESTful, idempotent, consistent error responses  
âœ… **Worker patterns**: Polling, retry logic, backoff, graceful shutdown  
âœ… **Type safety**: Zod schemas como single source of truth  
âœ… **Pragmatism**: MVP scope bem definido, incremental delivery

## ğŸ“ License

MIT
